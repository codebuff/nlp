Download Google bigram corpus: link
Assignment 1: Predict Next Word corpus: Twitter Corpus (given in the first assignment)
Steps:
1. Take random 5000 tweets. Divide them into 10 sets. Each set will be consisting of 500 words.
2. Automatically delete all the ith words from each tweet from the ith set. for example delete 5 the word from the set 5.
3. Predict the all the words using bigram, tri-gram and quad grams using Google n-grams.
4. Report me the average accuracy of the experiemts: using bigram, trigram and quadgram.
 
Assignment 2: Create your own Language Model: bigram and trigram from the Twitter Corpus
Steps:
Use the same 5K tweets for trainging
Use Laplace Smoothing
Calculate Perplexity on a new 5K set
Repeat the steps of Assigment 1 and report me the accuracy of your language model in comparison with Google n-gram
 
Assignment 3: Create Language Identifier
Steps:
Download the Corpus: link Divide it into training (60%), development (20%), and test(20%) set.
Create Language Profiles from the training set
unerstand the distance meausure: threshold from the development set.
Apply the same on the test set and report me the accuracy.
 
Assignment 4: Create word-level Language Identifier for Code-Mixed text
Steps:
Collect the Corpus from me via email Divide it into training (60%), development (20%), and test(20%) set.
Create Language Profiles from the training set: using character level ngrams
unerstand the distance meausure: threshold from the development set.
Apply the same on the test set and report me the accuracy.
